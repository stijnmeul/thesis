\chapter{Background}
\label{cha:1}
This chapter briefly covers the mathematical knowledge required to understand cryptographic algorithms presented later in this text. The mathematical details of this chapter represent a fundament of a challenging world containing exciting cryptographic concepts like identity-based encryption. If the reader feels he has sufficient background of the concepts covered in this chapter, the chapter can be skipped without loss of comprehension.

Note that this chapter only overviews the cryptographic fundamentals required to understand the remainder of the thesis. Definitions and theorems are always provided without proof. For a more in depth discussion about algebraic topics in this chapter, the reader is referred to~\cite{book:handbook_of_applied_cryptography} and~\cite{book:survey_of_modern_algebra}. More information on elliptic curves, Diffie-Hellman assumptions and pairing based cryptography can be found in~\cite{thesis:Maas04}.

For the remainder of this chapter, the notion of negligible functions is introduced, followed by an overview of algebraic structures and their properties. Then, a number of theoretic assumptions fundamental for cryptographic security are presented. The introduction of gap groups and bilinear maps follows naturally by exploring these variants of the Diffie-Hellman assumption. Finally, hash functions are defined as well as their relation to the random oracle assumption.

\section{Complexity Theory}
\subsection{Assymptotic Notation}

\subsection{Complexity Classes}
Polynomial time algorithm
(Sub)exponential-time algorithm

\subsection{Negligible Function}
In practice no modern cryptographic algorithm achieves perfect secrecy\footnote{Note that the one-time pad is not taken into account. Although it is the only proven information secure cryptographic algorithm, it is seldom used in practical cryptographic systems.}, i.e. with unbounded computational power all practical cryptographic algorithms can be broken. Therefore, a more pragmatic definition of security is usually considered, such as security against adversaries that are computationally bound to their finite resources. In this pragmatic view of security an algorithm is considered secure only if the probability of success is smaller than the reciprocal of any polynomial function. The negligible function can be used to exactly describe this notion in a formal way.

\begin{defn}
\label{def:negligible_function}
A \textbf{negligible function} in $\lambda$ is a function $\mu \left( \lambda \right): \mathbb{N} \rightarrow \mathbb{R}$ if for every polynomial $p \left( \cdot \right)$ there exists an $N$ such that for all $\lambda > N$~\cite{book:Goldreich97}
 \begin{equation*}
  \mu \left( \lambda \right) < \frac{1}{p\left( \lambda \right)} 
 \end{equation*}
\end{defn}

The negligible function is used along this chapter to formally describe computationally infeasible problems. In such a context $\lambda$ often represents the security parameter. The larger $\lambda$ will be chosen, the smaller $\mu \left( \lambda \right)$ will be.


\section{Probability Theory}

\subsection{Random Variables}
Definition of perfect randomness here
\subsection{Indistinguishability}

\section{Abstract Algebra}
Abstract algebra is a field of mathematics that studies algebraic structures such as groups, rings and vector spaces. These algebraic structures define a collection of requirements on mathematical sets such as e.g., the natural numbers $\mathbb{N}$ or matrices of dimension 2 x 2 $\mathbb{R}^{2 x 2}$. If these requirements hold, abstract properties can be derived. Once a mathematical set is then categorised as the correct algebraic structure, properties derived for the algebraic structure will hold for the set as a whole.

In the light of our further discussion, especially additive and multiplicative groups prove to be essential concepts. However, algebraic groups come with a specific vocabulary such as binary operation, group order and cyclic group that are defined in this section as well.

\begin{defn}[Binary operation]
 A \textit{binary operation} * on a set $S$ is a mapping $S \times S \rightarrow S$. That is, a binary operation is a rule which assigns to each ordered pair of elements $a$ and $b$ from $S$ a uniquely defined third element $c = a*b$ in the same set $S$.~\cite{book:survey_of_modern_algebra,book:handbook_of_applied_cryptography}
\end{defn}

\begin{defn}[Group]
\label{def:group}
 A \textit{group} $\left( G, * \right)$ consists of a set $G$ with a binary operation $*$ on $G$ satisfying the following three axioms:
 \begin{enumerate}
  \item \textit{Associativity} $\forall a, b, c \in G: a*(b*c) = (a*b)*c$
  \item \textit{Identity element} $\forall a \in G, \exists \; e \in G: a*e = e*a = a $ where $e$ denotes the \textit{identity element} of $G$
  \item \textit{Inverse element} $\forall a \in G, \exists \; a^{-1}: a*a^{-1} = a^{-1}*a = 1$ where $a^{-1}$ denotes the \textit{inverse element} of $a$
  \newcounter{enumTemp}
  \setcounter{enumTemp}{\theenumi}
 \end{enumerate}

\end{defn}

\begin{defn}[Commutative group]
 A group $\left( G, * \right)$ is called a \textit{commutative group} or an \textit{abelian group} if in addition to the properties in Definition~\ref{def:group}, also commutativity holds.
 \begin{enumerate}
  \setcounter{enumi}{\theenumTemp}
  \item \textbf{Commutativity} $\forall a, b \in G: a*b = b*a$
 \end{enumerate}

\end{defn}

Depending on the group operation~$*$, $\left( G, * \right)$ is either called a \textit{multiplicative group} or an \textit{additive group}. In Definition~\ref{def:group} the multiplicative notation is used. For an additive group  the inverse of $a$ is often denoted $- a$~\cite{book:handbook_of_applied_cryptography}. 

A group $\left( G, * \right)$ is often denoted by the more concise symbol $G$ although groups are always defined with respect to a binary group operation $*$. Despite of a more concise notation, any group $G$ still obeys all axioms from Definition~\ref{def:group} with respect to an implicitly known group operation $*$.

A perfect example of a commutative group is the set of integers with the addition operation $\left( \mathbb{Z}, + \right)$ since the addition is both associative and commutative in $\mathbb{Z}$. Furthermore, the identity element $e = 0$ and the inverse element $\forall a \in \mathbb{Z}$ is $-a \in \mathbb{Z}$. Note that the set of natural numbers with the addition operation $\left( \mathbb{N}, + \right)$ is not a commutative group as not every element of $\mathbb{N}$ has an inverse element.

\begin{defn}[Cyclic group]
\label{def:cyclic_group}
 A group $G$ is \textit{cyclic} if and only if $\forall b \in G, \exists g \in G,\exists n \in \mathbb{Z}: g^n = b$. Such an element $g$ is called a \textbf{generator} of $\mathbb{G}$.
\end{defn}

Definition~\ref{def:cyclic_group} implies that in a cyclic group every element can be written as a power of one of the group's generators.

\begin{defn}[Finite group]
\label{def:finite_group}
 A group $G$ is \textit{finite} if the number of elements in $G$ denoted $|G|$ is finite. The number of elements $|G|$ in a finite group is called the \textit{group order}.
\end{defn}

The set $\mathbb{Z}_n$ denotes the set of integers modulo $n$. The set $\mathbb{Z}_5$ with the addition operation is a cyclic finite group of order 5. The set $\mathbb{Z}_5 \backslash \{0\}$ with the multiplication operation, often denoted $\mathbb{Z}^{*}_5$, is a cyclic finite group of order 4 where the neutral element $e=1$. For example, 2 is a generator in $\mathbb{Z}^{*}_5$ since every element in $\mathbb{Z}^{*}_5$ can be written as $\{ 2^n | n \in \mathbb{Z} \}$.

\begin{defn}[Order of an element]
\label{def:order_of_an_element}
Let $G$ be a group. The \textit{order of an element} $a \in G$ is defined as the least positive integer $t$ such that $a^t = e$. If there exists no such $t$, $t$ is defined as~$\infty$.
\end{defn}

\begin{thm}
\label{the:group_modulo_a_prime}
If the order of a group $G$ equals a prime $p$, the group is cyclic and commutative.
\end{thm}

\begin{defn}[Subgroup]
\label{def:subgroup}
 Given a group $\left( G, * \right)$, any $H$ that is a non-empty subset $H \subseteq G$ and satisfies the axioms of a group with respect to the group operation $*$ in $H$, is a \textit{subgroup of $G$}.
\end{defn}

\begin{defn}[Ring]
\label{def:ring}
  \setcounter{enumTemp}{\theenumi}
 A \textit{ring} $\left( R, +, * \right)$ consists of a set $R$ with two binary operations $+$ and $*$ on $R$ satisfying the following axioms:
 \begin{enumerate}
  \item $\left( R, + \right)$ is an abelian group with identity denoted $e$
  \item \textit{Associativity} $\forall a, b, c \in R: a*(b*c) = (a*b)*c$
  \item \textit{Multiplicative identity element} $\forall a \in R, \exists 1 \in R: a*1 = 1*a = a $ where $1$ denotes the \textit{multiplicative identity element} of $R$
  \item \textit{Left distributivity} $\forall a, b, c \in R: a*\left( b + c \right) = \left( a * b \right) + \left( a * c \right)$
  \item \textit{Right distributivity} $\forall a, b, c \in R: \left( b + c \right) * a = \left( b * a \right) + \left( c * a \right)$
   \setcounter{enumTemp}{\theenumi}
 \end{enumerate}
\end{defn}

\begin{defn}[Commutative ring]
 \label{def:commutative_ring}
 A ring $\left( R, +, * \right)$ is called a \textit{commutative ring} or an \textit{abelian ring} if in addition to the properties in Definition~\ref{def:ring}, also commutativity holds.
 \begin{enumerate}
  \setcounter{enumi}{\theenumTemp}
  \item \textbf{Commutativity} $\forall a, b \in R: a*b = b*a$
  \setcounter{enumTemp}{\theenumi}
 \end{enumerate}

\end{defn}

\begin{defn}[Field]
\label{def:field}
 A commutative ring $\left( R, +, * \right)$is called a \textit{field} if in addition to the properties in Definition~\ref{def:commutative_ring} and Definition~\ref{def:ring} all elements of $R$ have a multiplicative inverse.
 \begin{enumerate}
  \setcounter{enumi}{\theenumTemp}
   \item \textit{Multiplicative inverse} $\forall a \in R, \exists a^{-1}: a*a^{-1} = a^{-1}*a = 1$ where $a^{-1}$ denotes the \textit{inverse element} of $a$
 \end{enumerate}
\end{defn}

\begin{defn}[Finite field]
\label{def:finite_field}
 A \textit{finite field} or a \textit{Galois Field} is a field $F$ with a finite number of elements. The number of elements $|F|$ of a finite field $F$ is called its \textit{order}.
\end{defn}

\begin{defn}[Ring homomorphism]
\label{def:ring_homomorphism}
 Given rings $R$ and $S$, a \textit{ring homomorphism} is a function $f: R \rightarrow S$ such that the following axioms hold:
 \begin{enumerate}
  \item $\forall a, b \in R: f \left( a + b \right) = f \left( a \right) + f \left( b \right)$
  \item $\forall a, b \in R: f \left( ab \right) = f \left( a \right) f \left( b \right)$
  \item $f \left( e_R \right) = f \left( e_S \right)$ where $e_S$ and $e_R$ denote the identity element of respectively $S$ and $R$
 \end{enumerate}
\end{defn}

\begin{defn}[Bijective function]
\label{def:bijective_function} 
 Any function $f: R \rightarrow S$ is bijective if it satisfies the following axioms
 \begin{enumerate}
  \item \textit{Injective} Each element in $S$ is the image of at most one element in $R$. Hence, $\forall a_1, a_2 \in R$ if $\left( a_1 \right) = f \left( a_2 \right)$ then $a_1 = a_2$ follows naturally.
  \item \textit{Surjective} Each $s \in S$ is the image of at least one $r \in R$.
 \end{enumerate}
\end{defn}

\begin{defn}[Ring isomorphism]
\label{def:ring_isomorphism}
 A ring isomorphism is a bijective homomorphism.
\end{defn}

Informally speaking, a ring isomorphism $f: R \rightarrow S$ is a mapping between rings that are structurally the same such that any element of $R$ has exactly one image in $S$.

Note that $\left( \mathbb{Z}_n, +, \cdot \right)$ is a finite field if and only if $n$ is a prime number. Furthermore, if $F$ is a finite field, then $F$ contains $p^m$ elements for some prime $p$ and integer $m \geq 1$. For every prime power order $p^m$, there is a unique finite field of order $p^m$. This field is denoted by $\mathbb{F}_{p^m}$ or $GF \left( p^m \right)$. The finite field $\mathbb{F}_{p^m}$ is unique up to an isomorphism. 


\section{Number Theoretic Assumptions}
\label{sec:number_theoretic_assumptions}
This section presents a collection of number theoretic assumptions. The cryptographic security of our future constructions falls or stands on these assumptions~\cite{art:Boneh98,book:handbook_of_applied_cryptography}.

In the definitions that follow $\left< G, n, g \right> \leftarrow \mathcal{G} \left( 1^{\lambda} \right)$ is defined as the setup algorithm that generates a group $G$ of order $n$ and a generator $g \in G$ on input of the security parameter $k$.

\begin{defn}[DL]
\label{def:dl}
The \textit{discrete logarithm problem} is defined as follows. Given a finite cyclic group $G$ of order $n$, a generator $g \in G$ and an element $a \in G$, find the integer $x, 0 \leq x \leq n-1$ such that $g^x = a$.

The \textit{discrete logarithm assumption} holds if for any algorithm $\mathcal{A} \left( g, g^x \right)$ trying to solve the DL problem there exists a negligible function $\mu \left( k \right)$ such that 
 \begin{equation*}
  \textrm{Pr} \left[ \mathcal{A} \left( g, g^x \right) = a \mid \left< G, n, g \right> \leftarrow \mathcal{G} \left( 1^{\lambda} \right)\right] \leq \mu \left( \lambda \right)
 \end{equation*}
 where the probability is over the random choice of $n, g$ in $G$ according to the distribution induced by $\mathcal{G} \left( 1^{\lambda} \right)$, the random choice of $a$ in $G$ and the random bits of the algorithm $\mathcal{A}$.
\end{defn}


\begin{defn}[CDH]
\label{def:cdh}
The \textit{Computational Diffie-Hellman problem} is defined as follows. Given a finite cyclic group $G$ of order $n$, a generator $g \in G$ and $g^a, g^b$ with uniformly chosen random independent elements $a, b \in \{ 1, \ldots, | G |\}$ , find the value $g^{ab}$.


The \textit{Computational Diffie-Hellman assumption} holds if for any algorithm $\mathcal{A} \left( g, g^a, g^b \right)$ trying to solve the CDH problem there exists a negligible function $\mu \left( k \right)$ such that 
 \begin{equation*}
  \textrm{Pr} \left[ \mathcal{A} \left( g, g^a, g^b \right) = g^{ab} \mid \left< G, n, g \right> \leftarrow \mathcal{G} \left( 1^{\lambda} \right)\right] \leq \mu \left( \lambda \right)
 \end{equation*}
 where the probability is over the random choice of $n, g$ in $G$ according to the distribution induced by $\mathcal{G} \left( 1^k \right)$, the random choice of $a, b$ in $\{ 1, \ldots, | G |\}$ and the random bits of the algorithm $\mathcal{A}$.
\end{defn}

\begin{defn}[DDH]
\label{def:ddh}
The \textit{Decisional Diffie-Hellman problem} is defined as follows. Given a finite cyclic group $G$ of order $n$, a generator $g \in G$ and $g^a, g^b, g^{ab}, g^c$ with uniformly chosen random independent elements $a, b, c \in \{ 1, \ldots, | G |\}$, distinguish $\left< g, g^a, g^b, g^{ab} \right>$ from $\left< g, g^a, g^b, g^c \right>$.

Define $\mathcal{A} \left( x \right)$ as an algorithm returning \texttt{true} if $x = \left< g, g^a, g^b, g^{ab} \right>$ and \texttt{false} if $x = \left< g, g^a, g^b, g^c \right>$ for $c \neq ab$. The \textit{Decisional Diffie-Hellman assumption} holds if for any such algorithm $\mathcal{A} \left( x \right)$ there exists a negligible function $\mu \left( k \right)$ such that 
 \begin{equation*}
  \lvert \textrm{Pr} \left[ \mathcal{A} \left( \left< g, g^a, g^b, g^{ab} \right> \right) = \texttt{true} \right] - \textrm{Pr} \left[ \mathcal{A} \left( \left< g, g^a, g^b, g^{c} \right> \right) = \texttt{true} \right] \rvert \leq \mu \left( \lambda \right)
 \end{equation*}
 where the probability is over the random choice of $n, g$ in $G$ according to the distribution induced by $\mathcal{G} \left( 1^{\lambda} \right)$, the random choice of $a, b, c$ in $\{ 1, \ldots, | G | \} $ and the random bits of the algorithm $\mathcal{A}$.
\end{defn}


Definition~\ref{def:ddh} states that $\left< g, g^a, g^b, g^{ab} \right>$ and $\left< g, g^a, g^b, g^{c} \right>$ are \textit{computationally indistinguishable}. This implies that no efficient algorithm exists that can distinguish both arguments with non-negligible probability. The concept of computational indistinguishability bears close resemblance to statistical indistinguishability. The reader is referred to~\cite{art:Goldwasser84,art:Goldwasser89} for a more in depth discussion of the topic. The intuitive interpretation of Definition~\ref{def:ddh} is that $g^{ab}$ looks like any other random element in $G$.

Someone with the ability to calculate discrete logarithms could trivially solve the CDH problem. That is, if $a$ and $b$ can be derived only from $\left< g^a, g^b \right>$, it becomes easy to calculate $g^{ab}$. Therefore, a group structure where the CDH assumption holds, immediately implies a group where the DL assumption is valid as well. There is no mathematical proof that supports the inverse relation. Thus, a group where the DL problem is hard not necessarily implies the CDH problem. For specific group structures the CDH assumption immediately follows from the DL assumption as shown in~\cite{art:MaurerW98,art:MaurerW99}. However, their proof can not be generalised to just any group.

There exists a similar relation between the CDH and the DDH problem. If a powerful algorithm could solve CDH, i.e. derive $g^{ab}$ from $\left< g, g^a, g^b \right>$ alone, it would become trivial to distinguish $\left< g, g^a, g^b, g^{ab} \right>$ from $\left< g, g^a, g^b, g^c \right>$. Again, an inverse relation can not be proven. As a matter of fact, concrete examples of groups exist where CDH is hard although DDH is not.

Therefore, the relation between DL, CDH and DDH is often written as follows
\begin{equation*}
 DDH \Rightarrow CDH \Rightarrow DL
\end{equation*}
The $\Rightarrow$ notation is then translated into ''immediately implies''. In a group where DDH is hard both CDH and DL will be hard. Contrarily, there exist group structures where the CDH and the DL assumption hold while DDH can be found easily. Such groups are called \textit{Gap Diffie-Hellman Groups}.

\begin{defn}[GDH]
\label{def:gdh}
The \textit{Gap Diffie-Hellman problem} is defined as follows. Solve the CDH problem with the help of a DDH oracle. Given a finite cyclic group $G$ of order $n$, a generator $g \in G$ and $g^a, g^b$ with uniformly chosen random independent elements $a, b \in \{ 1, \ldots, | G |\}$ , find the value $g^{ab}$ with the help of a DDH oracle $\mathcal{DDH} \left( g, g^a, g^b, z \right)$. Where the DDH oracle $\mathcal{DDH} \left( g, g^a, g^b, z \right)$ is defined to return \texttt{true} if $z = g^{ab}$ and \texttt{false} if $z \neq g^{ab}$.

The \textit{Gap Diffie-Hellman assumption} holds if for any algorithm $\mathcal{A} \left( g, g^a, g^b \right)$ trying to solve the CDH problem with the help of a DDH oracle $\mathcal{DDH} \left( g, g^a, g^b, z \right)$ there exists a negligible function $\mu \left( k \right)$ such that 
 \begin{equation*}
  \textrm{Pr} \left[ \mathcal{A} \left( g, g^a, g^b \right) = g^{ab} \mid \left< G, n, g \right> \leftarrow \mathcal{G} \left( 1^{\lambda} \right)\right] \leq \mu \left( \lambda \right)
 \end{equation*}
 where the probability is over the random choice of $n, g$ in $G$ according to the distribution induced by $\mathcal{G} \left( 1^{\lambda} \right)$, the random choice of $a, b$ in $\{ 1, \ldots, | G |\}$ and the random bits of the algorithm $\mathcal{A}$.
\end{defn}

\section{Bilinear Maps}
\label{sec:bilinear_map}

It can be shown that bilinear pairings are an example of a practical usable DDH oracle~\cite{art:JouxN03}.

\subsection{Definition}

\begin{defn}[Admissible bilinear map]
\label{def:admissibile_bilinear_map}
 Let $G_1, G_2$ and $G_T$ be three groups of order $q$ for some large prime $q$. An \textit{admissible bilinear map} $e: G_1 \times G_2 \rightarrow G_T$ is defined as a map from the gap groups $G_1$ and $G_2$ to the target group $G_T$ that satisfies the following properties:
 \begin{enumerate}
  \item \textit{Bilinearity} $\forall a, b \in \mathbb{Z}, \forall P \in G_1, \forall Q \in G_2: e \left( aP, bQ \right) = e \left( P, Q \right)^{ab}$
  \item \textit{Non-degeneracy} If $P$ is a generator of $G_1$ and $Q$ is a generator of $G_2$, $e \left( P, Q \right)$ is a generator of $G_T$
  \item \textit{Computability} There is an efficient algorithm to compute $e \left( P, Q \right)$ for all $P \in G_1$ and $Q \in G_2$
 \end{enumerate}

\end{defn}

In literature, authors distinguish two types of admissible bilinear maps: symmetric and asymmetric bilinear maps. A \textit{symmetric bilinear map} is an admissible bilinear map where the gap groups are the same, i.e. $G_1 = G_2$. Definition~\ref{def:admissibile_bilinear_map} describes the more general \textit{asymmetric bilinear map} where $G_1 \neq G_2$. Schemes relying on symmetric bilinear maps are easier to construct information theoretic security proofs although asymmetric bilinear maps are more efficient and suitable for implementation thanks to their flexible embedding degree~\cite{art:BonehF01,art:ZhangW13}.

In practice, bilinear maps are constructed using pairings. The most popular pairings implementing admissible bilinear maps are the Weil pairing~\cite{art:BonehF01} and the Tate pairing~\cite{art:FreyMR99}. Both the Tate and the Weil pairing rely on abelian varieties for their implementation. $G_1$ is mostly an additive elliptic curve group, $G_2$ a multiplicative elliptic curve group while $G_T$ is a finite field. For instance, the asymmetric Weil pairing is often implemented with a cyclic subgroup of $E\left( \mathbb{F}_p \right)$ of order $q$ for $G_2$ and a different cyclic subgroup of $E \left( \mathbb{F}_{p^6} \right)$ of the same order $q$ for $G_1$ where $E\left( \mathbb{F}_{p^6} \right)$ denotes the group of points on an elliptic curve $E$ over the finite field $\mathbb{F}_{p^6}$. The interested reader is referred to~\cite{thesis:Maas04} for more information concerning elliptic curves and their use in pairing based cryptography. Details on Elliptic Curve Cryptography fall out of the scope of this thesis as it suffices to make abstraction of these concepts for the remainder of the text.

Recent research~\cite{art:AdjMOR13,art:BarbulescuGJT14,art:Joux13} has has shown that the discrete logarithm problem is easier in the symmetric setting because symmetric pairings rely on more structured supersingular (hyper)elliptic curves. Therefore, it is discouraged to rely on symmetric pairings in practical implementations~\cite{art:ZhangW13}.

\subsection{Bilinear Diffie-Hellman Assumption}
A bilinear map allows to solve the Decisional Diffie-Hellman problem in $G_1$ and $G_2$. The DDH problem in $G_1$ consists of distinguishing $\left< P, aP, bP, abP \right>$ from $\left< P, aP, bP, cP \right>$ where $P \in G_1$, $P$ is a generator of $G_1$ and $a, b, c$ randomly chosen in $\{1, \ldots, \vert G_1 \vert \}$. Given a symmetric bilinear map $e: G_1 \times G_1 \rightarrow G_T$ a solution to this problem is found by relying on the bilinearity of the pairing as follows:

\begin{equation*}
 e \left( aP, bP \right) = e \left( P, P \right)^{ab} \stackrel{?}{=} e \left( P, cP \right) = e \left( P, P\right)^c
\end{equation*}
Such that the second equality will hold only if $ab = c$. A similar statement can be made concerning $G_2$ with the help of the map $e: G_2 \times G_2 \rightarrow G_T$. Consequently, $G_1$ and $G_2$ are both GDH groups. Since DDH (Definition~\ref{def:ddh}) is a stronger assumption than CDH (Definition~\ref{def:cdh}), CDH can still be hard in GDH groups~\cite{art:BonehF01}.

Since DDH in the Gap groups $G_1$ and $G_2$ is easy, DDH can not serve as a basis for crypto systems in these groups. Therefore, an alternative to the CDH problem is defined called the Bilinear Diffie-Hellman problem.

In the definition that follows $\mathcal{G} \left( 1^{\lambda} \right)$ is defined to be a BDH parameter generator as in~\cite{art:BonehF01}, i.e. $\mathcal{G}$ takes as input a security parameter $\lambda$, $\mathcal{G}$ runs in polynomial time in $\lambda$ and $\mathcal{G}$ outputs a prime number $q$, the description of two groups $G_1, G_2$ of order $q$ and the description of an admissible bilinear map $e: G_1 \times G_2 \rightarrow G_T$.
\begin{defn}[BDH]
\label{def:bdh}
The \textit{Bilinear Diffie-Hellman problem} is defined as follows. Given any admissible bilinear pairing $e: G_1 \times G_2 \rightarrow G_T$ with random $P, aP, bP \in G_1$ and random $Q, aQ, bQ \in G_2$ with uniformly chosen random independent elements $a, b, c \medskip \in \{ 1, \ldots, | G |\}$, find $e \left( P, Q \right)^{abc}$

The \textit{Bilinear Diffie-Hellman assumption} holds if for any algorithm \\ $\mathcal{A} \left( P, aP, bP, Q, aQ, bQ \right)$ trying to solve the BDH problem there exists a negligible function $\mu \left( k \right)$ such that 
 \begin{equation*}
  \textrm{Pr} \left[ \mathcal{A} \left( P, aP, bP, Q, aQ, bQ \right) = e \left( P, Q \right)^{abc} \mid \left< q, G_1, G_2, e \right> \leftarrow \mathcal{G} \left( 1^{\lambda} \right)\right] \leq \mu \left( \lambda \right)
 \end{equation*}
 where the probability is over the random choice of $q, G_1, G_2, e$ according to the distribution induced by $\mathcal{G} \left( 1^{\lambda} \right)$, the random choice of $a, b$ in $\{ 1, \ldots, | G |\}$ and the random bits of the algorithm $\mathcal{A}$.
\end{defn}
\section{Cryptography}
\textit{Cryptology} is the science describing how to hide confidential information. Cryptology consists of two complementary fields that continuously try to outwit each other: cryptography and cryptanalysis. On the one hand, \textit{cryptography} is the practice and study of techniques trying to hide information from undesired third parties. On the other hand, \textit{cryptanalysis} is the domain of cryptology trying to derive information from hidden data.

\subsection{Symmetric Cryptography}
Figure~\ref{fig:cryptosystem} shows a typical cryptographic system often shortened to ''cryptosystem''. In a typical cryptosystem one party (often called Alice) tries to send a message $m$ over an insecure channel to another party (often called Bob). The channel is insecure as third parties like Eve can eavesdrop on the channel to read out data that is being sent over.

\begin{figure}[H]
 \includegraphics[trim=40mm 120mm 40mm 120mm, clip]{img/cryptosystem.pdf}
 \caption{A cryptosystem~\cite{thesis:Wyseur09}}
 \label{fig:cryptosystem}
\end{figure}

\subsubsection{Confidentiality}
Figure~\ref{fig:cryptosystem} achieves confidentiality, i.e. the information in $m$ is protected from disclosure to unauthorised parties. To prevent eavesdroppers from reading out the message $m$, Alice and Bob have agreed on a key $k$ that is unknown to the outside world. Before sending a message $m$ over the insecure channel, Alice encrypts the message $m$ to a ciphertext $c$ under the secret key $k$ using an \textit{encryption algorithm} $E_k$ such that $c = E_k \left( m \right)$. Ideally $c$ looks like random gibberish to eavesdroppers like Eve. Bob can then read out the original plaintext message $m$ by applying the decryption algorithm $D_k$ under the same key $k$. Cryptosystems as the one described in Figure~\ref{fig:cryptosystem} are called \textit{symmetric} as both Alice and Bob have to use the same key $k$ for encryption and decryption. 

Most cryptosystems that are practically used today satisfy Kerchoff's principle~\cite{art:Kerckhoffs1883}. Kerchoff's principle states that although the encryption and decryption mechanism are known to the outside world, the cryptosystem assures confidentiality as long as the symmetric key $k$ remains secret.

\subsubsection{One-time Pad}
A simple symmetric encryption algorithm $E_k$ could be to XOR the binary message $m$ with a binary key $k$ such that the ciphertext is equal to $c = m \oplus k$. Decryption $D_k$ would then consist of an XOR operation with the same binary symmetric key $k$ such that $m = c \oplus k = \left( m \oplus k \right) \oplus k$.  In such a scheme, the key $k$ should be a random binary string with the same length as the plaintext message $m$. This scheme was originally proposed by Vernam and is therefore often called the \textit{Vernam scheme}.

Further research on the Vernam scheme by Mauborgne showed that the Vernam scheme can be proven information theoretic secure if $k$ is chosen completely random and used only once. Because of these requirements on the key $k$, the Vernam scheme is more widely known as the \textit{one-time pad}.

\subsubsection{Practical Encryption Algorithms}
Because the one-time pad is proven information theoretic secure, it can not be broken even if the adversary has access to unlimited computing power. Although this is a desirable property, the one-time pad is not frequently used in modern cryptosystems due to its impractical key management.

Suppose Alice and Bob have a lot of secret information to share. This would require that the a priori agreed key $k$ is long enough to hide all this information. Once the size of the message $m$ becomes larger than the key $k$, Alice and Bob should agree on new random bits in $k$ to secure the remainder of their conversation. In fact, they have to agree upfront on as much random bits in $k$ as there will be bits in the message $m$.

Because such large random symmetric keys $k$ are not practical in real-life applications, block cipher modes and stream ciphers are widely used. These are algorithms that accept a fixed size symmetric key but allow to encrypt larger messages $m$ by introducing deterministic pseudo randomness. As already mentioned in Section~\ref{sec:number_theoretic_assumptions}, these algorithms require a more pragmatic view on cryptography because they only ensure that disclosure of information is computationally difficult but not impossible. Common examples of block ciphers are AES and DES. They can be used in CFB, CTR or CFB mode to name a few. Stream ciphers include Trivium and RC4. For more information on block ciphers, stream ciphers and modes of operation the reader is referred to~\cite{book:handbook_of_applied_cryptography}.

\subsubsection{Authenticated Encryption}
\label{sec:authenticated_encryption}
An authenticated encryption scheme consists of two generic probabilistic polynomial time algorithms:

\begin{description}
 \item \texttt{AE.Encrypt($m, k$):} Encrypt is a secure symmetric encryption scheme that takes as input a plaintext $m$, an additional binary sequence $a$ and a symmetric key $k$. As a result \texttt{AE.Encrypt} generates ciphertext $c$ and authentication tag $t$ as output. Symbolically this is often denoted as  $\left< c, t \right> \leftarrow \mathtt{E}_k(m, a)$
 \item \texttt{AE.Decrypt($c, k$):} Decrypt is a secure symmetric decryption scheme that takes as input a ciphertext $c$, an additional binary sequence $a$ and a symmetric key $k$. As a result \texttt{AE.Decrypt} generates the original plaintext $m$ and an authentication tag $t$ as output. Symbolically this is often denoted as $\left< m, t \right> \leftarrow \mathtt{D}_k(c, a)$
\end{description}

The properties of a secure authenticated encryption scheme are such that it is hard to change the plaintext message $m$, the additional binary sequence $a$, the symmetric key $k$ or the ciphertext $c$ without altering the returned authentication tag $t$. Therefore, a recipient of a ciphertext $c$ and an authentication tag $t_1$ should only compare the returned authentication tag $t_2$ from $\left< m, t_2 \right> \leftarrow \mathtt{D}_k(c,a)$ with the received tag $t_1$ to be convinced that the ciphertext $c$ was generate on input of the same symmetric key $k$, plaintext message $m$ an binary sequence $a$. Since it is hard to alter the binary sequence $a$ without changing the authentication tag $t$, $a$ is often called the \textit{authenticated data}, i.e. data that is authenticated by the encryption scheme but not encrypted.

\subsection{Asymmetric Cryptography}
\label{sec:asymmetric_cryptography}
The concept behind asymmetric cryptography is to use a different key for encryption than decryption, thereby making secure communication easier between parties who have never met before. A background on the basic concepts of traditional asymmetric cryptography allows to put the conclusions of this chapter into context.

\subsubsection{Definition}
In a \textit{Public Key Infrastructure} (PKI) each entity $A$ has a key pair $\left< pk_A, sk_A \right>$ where $pk_A$ and $sk_A$ denote the public and the private key of entity $A$ respectively. The public key is publicly available, while the private key often remains secret and only known by $A$. The domain of cryptography describing the concept of these key pairs is often called \textit{asymmetric cryptography}. 

In asymmetric cryptography, key pair generation is a two step process. In the first step, the private key $sk$ is chosen uniformly random. In the second step, the public key $pk$ is derived by applying a one-way function to $sk$. The one-way property of the applied function implies that it is computationally hard to derive the public key from the private key, e.g. in the ElGamal encryption scheme~\cite{art:Elgamal85} the public key is calculated as $pk = g^{sk}$ in a group $\mathbb{Z}_p$ for some large prime $p$. As long as the DL assumption from Definition~\ref{def:dl} holds it is infeasible to derive $sk$ from $pk$.

The concept of two different keys enables a wide plethora of useful applications. Once all public keys of a PKI system are known, two entities who never met before can immediately setup secure communication by encrypting under the correct public keys. Asymmetric cryptography also enables these entities to authenticate their messages by relying on signature schemes. Authenticity of signatures then immediately follows from the privacy of $sk$.

\subsubsection{Signature Schemes}
A digital signature resembles a handwritten signature in that it proofs a particular person has approved a particular message. However, a digital signature is harder to forge than its handwritten counterpart due to the computational hardness assumptions digital signatures rely on. More specifically, a signature is a construction such that it can be checked with a public verifying key $vk_A$ whether the signature was generated by the corresponding private signing key $sk_A$.

\begin{defn}[Digital signature]
\label{def:digital_signature}
 A digital signature $S_A \left( m \right)$ associates a message $m$ with a known sender $A$ in such a way that a recipient $B$ is ensured about the following properties:
 \begin{enumerate}
  \item \textit{Authentication:} $B$ can be certain that $A$ is the sender of the message.
  \item \textit{Non-repudiation:} $A$ can not deny having sent the message $m$.
  \item \textit{Integrity:} $B$ can be certain that the message $m$ is delivered consistently, i.e. unaltered from how $A$ originally drafted the message $m$.
 \end{enumerate}
\end{defn}

Algorithm~\ref{alg:generic_signature_scheme} explains how a generic signature scheme is often constructed. Note that a signature scheme only shifts the authentication problem. Verification of a signature $S_A \left( m \right)$ only ensures the message $m$ originated from the owner of the key pair $\left< sk_A, vk_A \right>$.
\begin{algorithm}
\caption{Generic Signature Scheme }
\label{alg:generic_signature_scheme}
 \medskip
 In a digital signature scheme each entity $A$ has a publicly known verifying key $vk_A$ and a corresponding private signing key $sk_A$. A generic signature scheme consists of two algorithms:
 \begin{enumerate}
  \item \texttt{Sign($sk_A, m$)}: Entity $A$ signs the message $m$ using its private signing key $sk_A$ resulting in a signature $S_{sk_A} \left( m \right)$
  \item \texttt{Verify($pk_A, S_{sk_A} \left( m \right), m$)}: Entity $B$ verifies the signature $S_{sk_A} \left( m \right)$ with the public verifying key $vk_A$ of $A$. The \texttt{Verify} step returns \texttt{true} or \texttt{false} depending on the validity of the signature.
 \end{enumerate}
\end{algorithm}

\subsubsection{Commitment Schemes}
\label{sec:commitment_schemes}
A commitment scheme is an asymmetric cryptographic scheme that allows to commit to a certain value while keeping the exact value private. The value can be revealed later giving anyone who received the commitment the possibility to check whether the value was changed between the commitment phase and the revealing of the value.

More formally, a generic commitment scheme is composed of three probabilistic polynomial time algorithms:

\begin{description}
 \item \texttt{CS.Setup($1^{\lambda}$):} On input of a security parameter $\lambda$, generates the public parameters $params$ of the system
 \item \texttt{CS.Commit($params, m, r$):} Returns a commitment $c_{m,r}$ to a message $m$ and a random binary sequence $r$.
 \item \texttt{CS.Open($params, c_{m,r}, m', r'$):} On input of public parameters $params$, a commitment $c_{m,r}$, a message $m$ and a random binary sequence $r$ it returns \texttt{true} if $c_{m,r} \leftarrow $\texttt{CS.Commit($params, m, r$)} with $m = m'$ and $r = r'$ and \texttt{false} otherwise.
\end{description}

For a more elaborate discussion on commitment schemes the reader is referred to the original paper from Brassard et al.~\cite{art:BrassardCC88}.

\subsection{Hash Functions}
The concept of hash functions is required to further explain random oracles. Random oracles are a useful construction in proving certain cryptographic algorithms.

\label{sec:hash_functions}
\subsubsection{Definition}
A \textit{hash function} is a computationally efficient deterministic function mapping binary strings of arbitrary length to binary strings of some fixed length, called \textit{hash-values}.

Cryptographic hash functions have the following desirable properties:
\begin{itemize}
 \item \textit{Computability:} Given a binary string $m$, the hash value $h$ can be calculated efficiently $h = \texttt{hash} \left( m \right)$
 \item \textit{Pre-image resistance:} Given a hash value $h$, it is infeasible to calculate a corresponding binary string $m$ such that $h = \texttt{hash} \left( m \right)$
 \item \textit{Second pre-image resistance:} Given a binary string $m_1$, it is hard to find a different binary string $m_2$ such that $\texttt{hash} \left( m_1 \right) = \texttt{hash} \left( m_2 \right)$
 \item \textit{Strong collision resistance:} Given a \texttt{hash} function \texttt{hash(.)}, it is hard to find two different binary strings $m_1$ and $m_2$ such that $\texttt{hash} \left( m_1 \right) = \texttt{hash} \left( m_2 \right)$
\end{itemize}

Hash functions are useful for a wide variety of practical applications. For instance, hash functions serve as one way functions in password databases to relax sensitivity of the stored content. In addition, hash functions represent a valuable tool for data authentication and integrity checking. Another use of hash functions is in protocols involving a priori commitments. If the reader is new to the concept of hash functions, he is referred to~\cite{book:handbook_of_applied_cryptography} for an in depth discussion on the topic.

\subsubsection{Random Oracles}
A \textit{random oracle} is a theoretical black box that returns for each unique query a uniformly random chosen result from its output domain. A random oracle is deterministic, i.e. given a particular input it will always produce the same output.

In a perfect world hash functions can be considered random oracles. That is, if hash functions were perfect, their output would look like perfect random bit sequences. Therefore, hash functions are often considered random oracles in security proofs. Such security proofs are said to be \textit{proven secure in the random oracle model}. Proofs in the random oracle model first show that an algorithm is secure if a theoretical random oracle would be used. A next step of these security proofs is replacing the random oracle accesses by the computation of an appropriately chosen (hash) function $h$~\cite{art:BellareR93}. Algorithms that do not require such a construction in their security proof are said to be \textit{proven secure in the standard model}.

Although theoretical definitions of random oracles and hash functions are quite similar, some practical implementations of hash functions do not behave like random oracles at all. Canetti at al.~\cite{art:CanettiGH04} show that there exist signature and encryption schemes that are secure in the Random Oracle Model, although any implementation of the random oracle results in insecure schemes~\cite{art:CanettiGH04}. Coron et al. counter these findings with indifferentiability, i.e. if a hash function is indifferentiable from a random oracle the random oracle can be replaced by the hash function while maintaining a valid security proof~\cite{art:CoronDMP05}. Therefore, it is a common belief that proofs in the random oracle model provide some evidence that a system is secure. Although research results from Coron et al. are debated in~\cite{art:FleischmannGL10} and~\cite{art:RistenpartSS11}. In fact, indifferentiability from random oracles certainly contributed to the victory of Keccak in the NIST hash function competition for a new SHA-3 hashing standard as all final round hashing algorithms supported this property~\cite{art:BartheGHOB13}.

\section{Summary}
Now the reader has knowledge of the mathematic fundaments, more advanced cryptographic constructions like identity-based encryption, broadcast encryption and distributed key generation are revealed in Chapter 3.

The first part of this chapter introduced the concepts of a negligible function as well as algebraic structures such as groups and finite fields. These basic notions were used further on to define number theoretic hard problems that serve as a basis for security. From the discrete logarithm assumption, several variants of the Diffie-Hellman problem were introduced, eventually leading to the Gap Diffie-Hellman assumption. The notion of the Gap Diffie-Hellman assumption allowed to uncover gap groups and their use in admissible bilinear maps. The Bilinear Diffie-Hellman assumption was defined as a computationally infeasible problem for the construction of cryptographic protocols relying on bilinear maps. Finally, this chapter concluded with differences between security under random oracle assumptions and security in the standard model. 

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 
