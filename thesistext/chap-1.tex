\chapter{Background}
\label{cha:1}
This chapter covers briefly the mathematical knowledge required to understand cryptographic algorithms presented later in this text. Although understanding all mathematical details of this chapter can be quite a struggle, the math serves as a fundament of a challenging world containing exciting cryptographic concepts like identity-based encryption.

First, the notion of negligible functions will be introduced followed by an overview of algebraic structures and their properties. Then, a number of theoretic assumptions fundamental for cryptographic security are presented. By exploring these variants of the Diffie-Hellman assumption, the introduction of gap groups and bilinear maps follows naturally. Finally, hash functions are defined as well as their relation to the random oracle assumption.

Note that this chapter only scratches the surface of cryptographic fundamentals required to understand the remainder of the thesis. Definitions and theorems are always provided without proof. For a more in depth discussion about algebraic topics in this chapter, the reader is referred to~\cite{book:handbook_of_applied_cryptography} and~\cite{book:survey_of_modern_algebra}. More information on elliptic curves, Diffie-Hellman assumptions and pairing based cryptography can be found in~\cite{thesis:Maas04}.

If the reader feels he has sufficient background of the concepts covered in this chapter, the chapter can be skipped without loss of comprehension.

\section{Negligible Function}

In practice no modern cryptographic algorithm achieves perfect secrecy\footnote{Note that the one-time pad is not taken into account. Although it is the only proven information secure cryptographic algorithm, it is seldom used in practical cryptographic systems.}, i.e. with unbounded computational power all practical cryptographic algorithms can be broken. Therefore a more pragmatic definition of security is always considered, namely security against adversaries that are computationally bound to their finite resources. In this pragmatic view of security an algorithm is considered secure only if the probability of success is smaller than the reciprocal of any polynomial function. The negligible function can be used to exactly describe this notion in a formal way.

\begin{defn}
\label{def:negligible_function}
A \textbf{negligible function} in $k$ is a function $\mu \left( k \right): \mathbb{N} \rightarrow \mathbb{R}$ if for every polynomial $p \left( . \right)$ there exists an $N$ such that for all $k > N$~\cite{book:Goldreich97}
 \begin{equation*}
  \mu \left( k \right) < \frac{1}{p\left( k \right)} 
 \end{equation*}
\end{defn}

The negligible function will be used later on in this chapter to formally describe computationally infeasible problems. In such a context $k$ often represents the security parameter. The larger $k$ will be chosen, the smaller $\mu \left( k \right)$ will be.

\section{Abstract Algebra}
Abstract algebra is a field of mathematics that studies algebraic structures such as groups, rings and vector spaces. These algebraic structures define a collection of requirements on mathematical sets such as e.g., the natural numbers $\mathbb{N}$ or matrices of dimension 2 x 2 $\mathbb{R}^{2 x 2}$. If these requirements hold, abstract properties can be derived. Once a mathematical set is then categorised as the correct algebraic structure, properties derived for the algebraic structure will hold for the set as a whole.

In the light of our further discussion, especially additive and multiplicative groups prove to be essential concepts. However, algebraic groups come with a specific vocabulary such as binary operation, group order and cyclic group that are defined in this section as well.

\begin{defn}[Binary operation]
 A \textit{binary operation} * on a set $S$ is a mapping $S \times S \rightarrow S$. That is, a binary operation is a rule which assigns to each ordered pair of elements $a$ and $b$ from $S$ a uniquely defined third element $c = a*b$ in the same set $S$.~\cite{book:handbook_of_applied_cryptography,book:survey_of_modern_algebra}
\end{defn}

\begin{defn}[Group]
\label{def:group}
 A \textit{group} $\left( G, * \right)$ consists of a set $G$ with a binary operation $*$ on $G$ satisfying the following three axioms:
 \begin{enumerate}
  \item \textit{Associativity} $\forall a, b, c \in G: a*(b*c) = (a*b)*c$
  \item \textit{Identity element} $\forall a \in G, \exists e \in G: a*e = e*a = a $ where $e$ denotes the \textit{identity element} of $G$
  \item \textit{Inverse element} $\forall a \in G, \exists a^{-1}: a*a^{-1} = a^{-1}*a = 1$ where $a^{-1}$ denotes the \textit{inverse element} of $a$
  \newcounter{enumTemp}
  \setcounter{enumTemp}{\theenumi}
 \end{enumerate}

\end{defn}

\begin{defn}[Commutative group]
 A group $\left( G, * \right)$ is called a \textit{commutative group} or an \textit{abelian group} if in addition to the properties in Definition~\ref{def:group}, also commutativity holds.
 \begin{enumerate}
  \setcounter{enumi}{\theenumTemp}
  \item \textbf{Commutativity} $\forall a, b \in G: a*b = b*a$
 \end{enumerate}

\end{defn}

Depending on the group operation~$*$, $\left( G, * \right)$ is called either a \textit{multiplicative group} or an \textit{additive group}. In Definition~\ref{def:group} the multiplicative notation is used. For an additive group  the inverse of $a$ is often denoted $-a$~\cite{book:handbook_of_applied_cryptography}. 

A group $\left( G, * \right)$ is often denoted by the more concise symbol $G$ although groups are always defined with respect to a binary group operation $*$. Despite of a more concise notation, any group $G$ still obeys all axioms from Definition~\ref{def:group} with respect to an implicitly known group operation $*$.

A perfect example of a commutative group is the set of integers with the addition operation $\left( \mathbb{Z}, + \right)$ since the addition is both associative and commutative in $\mathbb{Z}$. Furthermore, the identity element $e = 0$ and the inverse element $\forall a \in \mathbb{Z}$ is $-a \in \mathbb{Z}$. Note that the set of natural numbers with the addition operation $\left( \mathbb{N}, + \right)$ is not a commutative group as not every element of $\mathbb{N}$ has an inverse element.

\begin{defn}[Cyclic group]
\label{def:cyclic_group}
 A group $G$ is \textit{cyclic} if and only if $\forall b \in G, \exists g \in G,\exists n \in \mathbb{Z}: g^n = b$. Such an element $g$ is called a \textbf{generator} of $\mathbb{G}$.
\end{defn}

Definition~\ref{def:cyclic_group} implies that in a cyclic group every element can be written as a power of one of the group's generators.

\begin{defn}[Finite group]
\label{def:finite_group}
 A group $G$ is \textit{finite} if the number of elements in $G$ denoted $|G|$ is finite. The number of elements $|G|$ in a finite group is called the \textit{group order}.
\end{defn}

The set $\mathbb{Z}_n$ denotes the set of integers modulo $n$. The set $\mathbb{Z}_5$ with the addition operation is a cyclic finite group of order 5. The set $\mathbb{Z}_5 \backslash \{0\}$ with the multiplication operation, often denoted $\mathbb{Z}^{*}_5$, is a cyclic finite group of order 4 where the neutral element $e=1$. Two is an example of a generator in $\mathbb{Z}^{*}_5$ since every element in $\mathbb{Z}^{*}_5$ can be written as $\{ 2^n | n \in \mathbb{Z} \}$.

\begin{defn}[Order of an element]
\label{def:order_of_an_element}
Let $G$ be a group. The \textit{order of an element} $a \in G$ is defined as the least positive integer $t$ such that $a^t = e$. If there exists no such $t$, $t$ is defined as~$\infty$.
\end{defn}

\begin{thm}
\label{the:group_modulo_a_prime}
If the order of a group $G$ equals a prime $p$, the group is cyclic and commutative.
\end{thm}

\begin{defn}[Subgroup]
\label{def:subgroup}
 Given a group $\left( G, * \right)$, any $H$ that is a non-empty subset $H \subseteq G$ and satisfies the axioms of a group with respect to the group operation $*$ in $H$, is a \textit{subgroup of $G$}.
\end{defn}

\begin{defn}[Ring]
\label{def:ring}
  \setcounter{enumTemp}{\theenumi}
 A \textit{ring} $\left( R, +, * \right)$ consists of a set $R$ with two binary operations $+$ and $*$ on $R$ satisfying the following axioms:
 \begin{enumerate}
  \item $\left( R, + \right)$ is an abelian group with identity denoted $e$
  \item \textit{Associativity} $\forall a, b, c \in R: a*(b*c) = (a*b)*c$
  \item \textit{Multiplicative identity element} $\forall a \in R, \exists 1 \in R: a*1 = 1*a = a $ where $1$ denotes the \textit{multiplicative identity element} of $R$
  \item \textit{Left distributivity} $\forall a, b, c \in R: a*\left( b + c \right) = \left( a * b \right) + \left( a * c \right)$
  \item \textit{Right distributivity} $\forall a, b, c \in R: \left( b + c \right) * a = \left( b * a \right) + \left( c * a \right)$
   \setcounter{enumTemp}{\theenumi}
 \end{enumerate}
\end{defn}

\begin{defn}[Commutative ring]
 \label{def:commutative_ring}
 A ring $\left( R, +, * \right)$ is called a \textit{commutative ring} or an \textit{abelian ring} if in addition to the properties in Definition~\ref{def:ring}, also commutativity holds.
 \begin{enumerate}
  \setcounter{enumi}{\theenumTemp}
  \item \textbf{Commutativity} $\forall a, b \in R: a*b = b*a$
  \setcounter{enumTemp}{\theenumi}
 \end{enumerate}

\end{defn}

\begin{defn}[Field]
\label{def:field}
 A commutative ring $\left( R, +, * \right)$is called a \textit{field} if in addition to the properties in Definition~\ref{def:commutative_ring} and Definition~\ref{def:ring} all elements of $R$ have a multiplicative inverse.
 \begin{enumerate}
  \setcounter{enumi}{\theenumTemp}
   \item \textit{Multiplicative inverse} $\forall a \in R, \exists a^{-1}: a*a^{-1} = a^{-1}*a = 1$ where $a^{-1}$ denotes the \textit{inverse element} of $a$
 \end{enumerate}
\end{defn}

\begin{defn}[Finite field]
\label{def:finite_field}
 A \textit{finite field} or a \textit{Galois Field} is a field $F$ with a finite number of elements. The number of elements $|F|$ of a finite field $F$ is called its \textit{order}.
\end{defn}

\begin{defn}[Ring homomorphism]
\label{def:ring_homomorphism}
 Given rings $R$ and $S$, a \textit{ring homomorphism} is a function $f: R \rightarrow S$ such that the following axioms hold:
 \begin{enumerate}
  \item $\forall a, b \in R: f \left( a + b \right) = f \left( a \right) + f \left( b \right)$
  \item $\forall a, b \in R: f \left( ab \right) = f \left( a \right) f \left( b \right)$
  \item $f \left( e_R \right) = f \left( e_S \right)$ where $e_S$ and $e_R$ denote the identity element of respectively $S$ and $R$
 \end{enumerate}
\end{defn}

\begin{defn}[Bijective function]
\label{def:bijective_function} 
 Any function $f: R \rightarrow S$ is bijective if it satisfies the following axioms
 \begin{enumerate}
  \item \textit{Injective} Each element in $S$ is the image of at most one element in $R$. Hence, $\forall a_1, a_2 \in R$ if $\left( a_1 \right) = f \left( a_2 \right)$ then $a_1 = a_2$ follows naturally.
  \item \textit{Surjective} Each $s \in S$ is the image of at least one $r \in R$.
 \end{enumerate}
\end{defn}

\begin{defn}[Ring isomorphism]
\label{def:ring_isomorphism}
 A ring isomorphism is a bijective homomorphism.
\end{defn}

Informally speaking, a ring isomorphism $f: R \rightarrow S$ is a mapping between rings that are structurally the same such that any element of $R$ has exactly one image in $S$.

Note that $\left( \mathbb{Z}_n, +, \cdot \right)$ is a finite field if and only if $n$ is a prime number. Furthermore, if $F$ is a finite field, then $F$ contains $p^m$ elements for some prime $p$ and integer $m \geq 1$. For every prime power order $p^m$, there is a unique finite field of order $p^m$. This field is denoted by $\mathbb{F}_{p^m}$ or $GF \left( p^m \right)$. The finite field $\mathbb{F}_{p^m}$ is unique up to an isomorphism. 


\section{Number Theoretic Assumptions}
\label{sec:number_theoretic_assumptions}
This section presents a collection of number theoretic assumptions. The security of our future constructions falls or stands on these assumptions. If one of these assumptions would prove to be invalid, not only this thesis would be superfluous, society would no longer be protected by widely adopted cryptographic protocols like RSA or ElGamal encryption~\cite{art:Boneh98,book:handbook_of_applied_cryptography}.

In the definitions that follow $\left< G, n, g \right> \leftarrow \mathcal{G} \left( 1^k \right)$ is defined as the setup algorithm that generates a group $G$ of order $n$ and a generator $g \in G$ on input of the security parameter $k$.

\begin{defn}[DL]
\label{def:dl}
The \textit{discrete logarithm problem} is defined as follows. Given a finite cyclic group $G$ of order $n$, a generator $g \in G$ and an element $a \in G$, find the integer $x, 0 \leq x \leq n-1$ such that $g^x = a$.

The \textit{discrete logarithm assumption} holds if for any algorithm $\mathcal{A} \left( g, g^x \right)$ trying to solve the DL problem there exists a negligible function $\mu \left( k \right)$ such that 
 \begin{equation*}
  \textrm{Pr} \left[ \mathcal{A} \left( g, g^x \right) = a \mid \left< G, n, g \right> \leftarrow \mathcal{G} \left( 1^{k} \right)\right] \leq \mu \left( k \right)
 \end{equation*}
 where the probability is over the random choice of $n, g$ in $G$ according to the distribution induced by $\mathcal{G} \left( 1^k \right)$, the random choice of $a$ in $G$ and the random bits of the algorithm $\mathcal{A}$.
\end{defn}


\begin{defn}[CDH]
\label{def:cdh}
The \textit{Computational Diffie-Hellman problem} is defined as follows. Given a finite cyclic group $G$ of order $n$, a generator $g \in G$ and $g^a, g^b$ with uniformly chosen random independent elements $a, b \in \{ 1, \ldots, | G |\}$ , find the value $g^{ab}$.


The \textit{Computational Diffie-Hellman assumption} holds if for any algorithm $\mathcal{A} \left( g, g^a, g^b \right)$ trying to solve the CDH problem there exists a negligible function $\mu \left( k \right)$ such that 
 \begin{equation*}
  \textrm{Pr} \left[ \mathcal{A} \left( g, g^a, g^b \right) = g^{ab} \mid \left< G, n, g \right> \leftarrow \mathcal{G} \left( 1^{k} \right)\right] \leq \mu \left( k \right)
 \end{equation*}
 where the probability is over the random choice of $n, g$ in $G$ according to the distribution induced by $\mathcal{G} \left( 1^k \right)$, the random choice of $a, b$ in $\{ 1, \ldots, | G |\}$ and the random bits of the algorithm $\mathcal{A}$.
\end{defn}

\begin{defn}[DDH]
\label{def:ddh}
The \textit{Decisional Diffie-Hellman problem} is defined as follows. Given a finite cyclic group $G$ of order $n$, a generator $g \in G$ and $g^a, g^b, g^{ab}, g^c$ with uniformly chosen random independent elements $a, b, c \in \{ 1, \ldots, | G |\}$, distinguish $\left< g, g^a, g^b, g^{ab} \right>$ from $\left< g, g^a, g^b, g^c \right>$.

Define $\mathcal{A} \left( x \right)$ as an algorithm returning \texttt{true} if $x = \left< g, g^a, g^b, g^{ab} \right>$ and \texttt{false} if $x = \left< g, g^a, g^b, g^c \right>$ for $c \neq ab$. The \textit{Decisional Diffie-Hellman assumption} holds if for any such algorithm $\mathcal{A} \left( x \right)$ there exists a negligible function $\mu \left( k \right)$ such that 
 \begin{equation*}
  \lvert \textrm{Pr} \left[ \mathcal{A} \left( \left< g, g^a, g^b, g^{ab} \right> \right) = \texttt{true} \right] - \textrm{Pr} \left[ \mathcal{A} \left( \left< g, g^a, g^b, g^{c} \right> \right) = \texttt{true} \right] \rvert \leq \mu \left( k \right)
 \end{equation*}
 where the probability is over the random choice of $n, g$ in $G$ according to the distribution induced by $\mathcal{G} \left( 1^k \right)$, the random choice of $a, b, c$ in $\{ 1, \ldots, | G | \} $ and the random bits of the algorithm $\mathcal{A}$.
\end{defn}


Definition~\ref{def:ddh} states that $\left< g, g^a, g^b, g^{ab} \right>$ and $\left< g, g^a, g^b, g^{c} \right>$ are \textit{computationally indistinguishable}. It means that no efficient algorithm exists that can distinguish both arguments with non-negligible probability. The concept of computational indistinguishable arguments bears close resemblance to statistically indistinguishable ensembles. The reader is referred to~\cite{art:Goldwasser84} and~\cite{art:Goldwasser89} for a more in depth discussion of the topic. The intuitive interpretation of Definition~\ref{def:ddh} is that $g^{ab}$ looks like any other random element in $G$.

Someone with the ability to calculate discrete logarithms could trivially solve the CDH problem. That is, if $a$ and $b$ can be derived only from $\left< g^a, g^b \right>$, it becomes easy to calculate $g^{ab}$. Therefore, a group structure where the CDH assumption holds, immediately implies a group where the DL assumption is valid as well. There is no mathematical proof that supports the inverse relation. Thus, a group where the DL problem is hard not necessarily implies the CDH problem. For specific group structures~\cite{art:MaurerW98} and~\cite{art:MaurerW99} show that CDH immediately follows from the DL assumption, however, their proof can not be generalised to just any group.

There exists a similar relation between the CDH and the DDH problem. If a powerful algorithm could solve CDH, i.e. derive $g^{ab}$ from $\left< g, g^a, g^b \right>$ alone, it would become trivial to distinguish $\left< g, g^a, g^b, g^{ab} \right>$ from $\left< g, g^a, g^b, g^c \right>$. Again, an inverse relation can not be proven. As a matter of fact, concrete examples of groups exist where CDH is hard although DDH is not.

Therefore, the relation between DL, CDH and DDH is often written as follows
\begin{equation*}
 DDH \Rightarrow CDH \Rightarrow DL
\end{equation*}
The $\Rightarrow$ notation is then translated into "immediately implies". In a group where DDH is hard both CDH and DL will be hard. On the contrary, there exist group structures where the CDH and the DL assumption hold while DDH can be found easily. Such groups are called \textit{Gap Diffie-Hellman Groups}.

\begin{defn}[GDH]
\label{def:gdh}
The \textit{Gap Diffie-Hellman problem} is defined as follows. Solve the CDH problem with the help of a DDH oracle. Given a finite cyclic group $G$ of order $n$, a generator $g \in G$ and $g^a, g^b$ with uniformly chosen random independent elements $a, b \in \{ 1, \ldots, | G |\}$ , find the value $g^{ab}$ with the help of a DDH oracle $\mathcal{DDH} \left( g, g^a, g^b, z \right)$. Where the DDH oracle $\mathcal{DDH} \left( g, g^a, g^b, z \right)$ is defined to return \texttt{true} if $z = g^{ab}$ and \texttt{false} if $z \neq g^{ab}$.

The \textit{Gap Diffie-Hellman assumption} holds if for any algorithm $\mathcal{A} \left( g, g^a, g^b \right)$ trying to solve the CDH problem with the help of a DDH oracle $\mathcal{DDH} \left( g, g^a, g^b, z \right)$ there exists a negligible function $\mu \left( k \right)$ such that 
 \begin{equation*}
  \textrm{Pr} \left[ \mathcal{A} \left( g, g^a, g^b \right) = g^{ab} \mid \left< G, n, g \right> \leftarrow \mathcal{G} \left( 1^{k} \right)\right] \leq \mu \left( k \right)
 \end{equation*}
 where the probability is over the random choice of $n, g$ in $G$ according to the distribution induced by $\mathcal{G} \left( 1^k \right)$, the random choice of $a, b$ in $\{ 1, \ldots, | G |\}$ and the random bits of the algorithm $\mathcal{A}$.
\end{defn}

As discussed in the next Section~\ref{sec:bilinear_map} bilinear pairings are an example of a practical usable DDH oracle~\cite{art:JouxN03}.

\section{Bilinear Maps}
\label{sec:bilinear_map}

\subsection{Definition}

\begin{defn}[Admissible bilinear map]
\label{def:admissibile_bilinear_map}
 Let $G_1, G_2$ and $G_T$ be three groups of order $q$ for some large prime $q$. An \textit{admissible bilinear map} $e: G_1 \times G_2 \rightarrow G_T$ is defined as a map from the gap groups $G_1$ and $G_2$ to the target group $G_T$ that satisfies the following properties:
 \begin{enumerate}
  \item \textit{Bilinearity} $\forall a, b \in \mathbb{Z}, \forall P \in G_1, \forall Q \in G_2: e \left( aP, bQ \right) = e \left( P, Q \right)^{ab}$
  \item \textit{Non-degeneracy} If $P$ is a generator of $G_1$ and $Q$ is a generator of $G_2$, $e \left( P, Q \right)$ is a generator of $G_T$
  \item \textit{Computability} There is an efficient algorithm to compute $e \left( P, Q \right)$ for all $P \in G_1$ and $Q \in G_2$
 \end{enumerate}

\end{defn}

In literature, authors distinguish two types of admissible bilinear maps. A \textit{symmetric bilinear map} is an admissible bilinear map where the gap groups are the same, i.e. $G_1 = G_2$. Definition~\ref{def:admissibile_bilinear_map} describes the more general \textit{asymmetric bilinear map} where $G_1 \neq G_2$. Schemes relying on symmetric bilinear maps are easier to construct information theoretic security proofs although asymmetric bilinear maps are more efficient and suitable for implementation thanks to their flexible embedding degree~\cite{art:BonehF01,art:ZhangW13}.

In practice, bilinear maps are constructed using pairings. The most popular pairings implementing admissible bilinear maps are the Weil pairing~\cite{art:BonehF01} and the Tate pairing~\cite{art:FreyMR99}. Both the Tate and the Weil pairing rely on abelian varieties for their implementation. $G_1$ is mostly an additive elliptic curve group, $G_2$ a multiplicative elliptic curve group while $G_T$ is a finite field. For instance, the asymmetric Weil pairing is often implemented with a cyclic subgroup of $E\left( \mathbb{F}_p \right)$ of order $q$ for $G_2$ and a different cyclic subgroup of $E \left( \mathbb{F}_{p^6} \right)$ of the same order $q$ for $G_1$ where $E\left( \mathbb{F}_{p^6} \right)$ denotes the group of points on an elliptic curve $E$ over the finite field $\mathbb{F}_{p^6}$. The interested reader is referred to~\cite{thesis:Maas04} for more information concerning elliptic curves and their use in pairing based cryptography. Details on Elliptic Curve Cryptography fall out of the scope of this thesis as it suffices to make abstraction of these concepts for the remainder of the text.

Research~\cite{art:BarbulescuGJT14,art:Joux13,art:AdjMOR13} has recently shown that the discrete logarithm problem is easier in the symmetric setting because symmetric pairings rely on more structured supersingular (hyper)elliptic curves. Therefore, care should be taken when using symmetric pairings~\cite{art:ZhangW13}.

\subsection{Bilinear Diffie-Hellman Assumption}
It is not a coincidence that $G_1$ and $G_2$ are called gap groups. A bilinear map allows to solve the Decisional Diffie-Hellman problem in $G_1$ and $G_2$. The DDH problem in $G_1$ consists of distinguishing $\left< P, aP, bP, abP \right>$ from $\left< P, aP, bP, cP \right>$ where $P \in G_1$, $P$ is a generator of $G_1$ and $a, b, c$ randomly chosen in $\{1, \ldots, \vert G_1 \vert \}$. Given a symmetric bilinear map $e: G_1 \times G_1 \rightarrow G_T$ a solution to this problem can be found by relying on the bilinearity of the pairing as follows:

\begin{equation*}
 e \left( aP, bP \right) = e \left( P, P \right)^{ab} \stackrel{?}{=} e \left( P, cP \right) = e \left( P, P\right)^c
\end{equation*}
Such that the second equality will hold only if $ab = c$. A similar statement can be made concerning $G_2$ with the help of the map $e: G_2 \times G_2 \rightarrow G_T$. Consequently $G_1$ and $G_2$ are both GDH groups. From Section~\ref{sec:number_theoretic_assumptions} it follows that CDH can still be hard in GDH groups because DDH is a stronger assumption~\cite{art:BonehF01}.

Since DDH in the Gap groups $G_1$ and $G_2$ is easy, DDH can not serve as a basis for crypto systems in these groups. Therefore, an alternative to the CDH problem is defined called the Bilinear Diffie-Hellman problem.

In the definition that follows $\mathcal{G} \left( 1^k \right)$ is defined to be a BDH parameter generator as in~\cite{art:BonehF01}, i.e. $\mathcal{G}$ takes as input a security parameter $k$, $\mathcal{G}$ runs in polynomial time in $k$ and $\mathcal{G}$ outputs a prime number $q$, the description of two groups $G_1, G_2$ of order $q$ and the description of an admissible bilinear map $e: G_1 \times G_2 \rightarrow G_T$ .
\begin{defn}[BDH]
\label{def:bdh}
The \textit{Bilinear Diffie-Hellman problem} is defined as follows. Given any admissible bilinear pairing $e: G_1 \times G_2 \rightarrow G_T$ with random $P, aP, bP \in G_1$ and random $Q, aQ, bQ \in G_2$ with uniformly chosen random independent elements $a, b, c \in \{ 1, \ldots, | G |\}$, find $e \left( P, Q \right)^{abc}$

The \textit{Bilinear Diffie-Hellman assumption} holds if for any algorithm \\ $\mathcal{A} \left( P, aP, bP, Q, aQ, bQ \right)$ trying to solve the BDH problem there exists a negligible function $\mu \left( k \right)$ such that 
 \begin{equation*}
  \textrm{Pr} \left[ \mathcal{A} \left( P, aP, bP, Q, aQ, bQ \right) = e \left( P, Q \right)^{abc} \mid \left< q, G_1, G_2, e \right> \leftarrow \mathcal{G} \left( 1^{k} \right)\right] \leq \mu \left( k \right)
 \end{equation*}
 where the probability is over the random choice of $q, G_1, G_2, e$ according to the distribution induced by $\mathcal{G} \left( 1^k \right)$, the random choice of $a, b$ in $\{ 1, \ldots, | G |\}$ and the random bits of the algorithm $\mathcal{A}$.
\end{defn}

\section{Hash Functions}
\label{sec:hash_functions}
\subsection{Definition}
A \textit{hash function} is a computationally efficient deterministic function mapping binary strings of arbitrary length to binary strings of some fixed length, called \textit{hash-values}.

Cryptographic hash functions have the following desirable properties:
\begin{itemize}
 \item \textit{Computability:} Given a binary string $m$, the hash value $h$ can be calculated efficiently $h = \texttt{hash} \left( m \right)$
 \item \textit{Pre-image resistance:} Given a hash value $h$, it is infeasible to calculate a corresponding binary string $m$ such that $h = \texttt{hash} \left( m \right)$
 \item \textit{Second pre-image resistance:} Given a binary string $m_1$, it is hard to find a different binary string $m_2$ such that $\texttt{hash} \left( m_1 \right) = \texttt{hash} \left( m_2 \right)$
 \item \textit{Strong collision resistance:} Given a \texttt{hash} function \texttt{hash(.)}, it is hard to find two different binary strings $m_1$ and $m_2$ such that $\texttt{hash} \left( m_1 \right) = \texttt{hash} \left( m_2 \right)$
\end{itemize}

Hash functions are useful in a wide plethora of practical applications. Hash functions serve as one way functions in password databases to relax sensitivity of the stored content. Furthermore hash functions are a valuable tool for data authentication and integrity checking. Another use of hash functions is in protocols involving a priori commitments. If the reader is new to the concept of hash functions, he is referred to~\cite{book:handbook_of_applied_cryptography} for an in depth discussion on the topic.

\subsection{Random Oracles}
A \textit{random oracle} is a theoretical black box that returns for each unique query a uniformly random chosen result from its output domain. A random oracle is deterministic, i.e. given a particular input it will always produce the same output.

In a perfect world hash functions can be considered random oracles. That is, if hash functions were perfect, they would behave as random oracles. Therefore, hash functions are often considered random oracles in security proofs. Such security proofs are said to be \textit{proven secure in the random oracle model}. Proofs in the random oracle model first show that an algorithm is secure if a theoretical random oracle would be used. A next step of these security proofs is replacing the random oracle accesses by the computation of an appropriately chosen (hash) function $h$~\cite{art:BellareR93}. Algorithms that do not require such a construction in their security proof are said to be \textit{proven secure in the standard model}.

Although theoretical definitions of random oracles and hash functions are quite similar, some practical implementations of hash functions do not behave like random oracles at all. Canetti at al. show that there exist signature and encryption schemes that are secure in the Random Oracle Model, although any implementation of the random oracle results in insecure schemes~\cite{art:CanettiGH04}. Coron et al. counter these findings with indifferentiability, i.e. if a hash function is indifferentiable from a random oracle the random oracle can be replaced by the hash function while maintaining a valid security proof~\cite{art:CoronDMP05}. Although research results from Coron et al. are debated in~\cite{art:FleischmannGL10} and~\cite{art:RistenpartSS11}, it is a common belief that proofs in the random oracle model provide some evidence that a system is secure. As a matter of fact, indifferentiability from random oracles certainly contributed to the victory of Keccak in the NIST hash function competition for a new SHA-3 hashing standard as all final round hashing algorithms supported this property~\cite{art:BartheGHOB13}.

\section{Cryptology - this section is temporary moved from chapter 3}
Cryptology is the science describing how to hide confidential information. Cryptology consists of two complementary fields that continuously try to outwit each other: cryptography and cryptanalysis. On the one hand, cryptography is the practice and study of techniques trying to hide information from undesired third parties. On the other hand, cryptanalysis is the domain of cryptology trying to derive information from hidden data.

\subsection{Symmetric Cryptography}
Figure~\ref{fig:cryptosystem} shows a typical cryptographic system often shortened to "cryptosystem". In a typical cryptosystem one party (often called Alice) tries to send a message $m$ over an insecure channel to another party (often called Bob). The channel is insecure as third parties like Eve can eavesdrop on the channel to read out data that is being sent over.

\begin{figure}
 \includegraphics[trim=40mm 120mm 40mm 120mm, clip]{img/cryptosystem.pdf}
 \caption{A cryptosystem~\cite{thesis:Wyseur09}}
 \label{fig:cryptosystem}
\end{figure}

\subsubsection{Confidentiality}
Figure~\ref{fig:cryptosystem} achieves confidentiality, i.e. the information in $m$ is protected from disclosure to unauthorised parties. To prevent eavesdroppers from reading out the message $m$, Alice and Bob have agreed on a key $k$ that is unknown to the outside world. Before sending a message $m$ over the insecure channel, Alice encrypts the message $m$ to a ciphertext $c$ under the secret key $k$ using an encryption algorithm $E_k$ such that $c = E_k \left( m \right)$. Ideally $c$ looks like random gibberish to eavesdroppers like Eve. Bob can then read out the original plaintext message $m$ by applying the decryption algorithm $D_k$ under the same key $k$. Cryptosystems as the one described in Figure~\ref{fig:cryptosystem} are called \textit{symmetric} as both Alice and Bob have to use the same key $k$ for encryption and decryption. 

Most cryptosystems that are practically used today satisfy Kerchoff's principle. Kerchoff's principle states that although the encryption and decryption mechanism are known to the outside world, the cryptosystem assures confidentiality as long as the symmetric key $k$ remains secret.

\subsubsection{One-time Pad}
A simple symmetric encryption algorithm $E_k$ could be to XOR the binary message $m$ with a binary key $k$ such that the ciphertext is equal to $c = m \oplus k$. Decryption $D_k$ would then consist of an XOR operation with the same binary symmetric key $k$ such that $m = c \oplus k = \left( m \oplus k \right) \oplus k$.  In such a scheme, the key $k$ should be a random binary string with the same length as the plaintext message $m$. This scheme was originally proposed by Vernam and is therefore often called the \textit{Vernam scheme}.

Further research on the Vernam scheme by Mauborgne showed that the Vernam scheme can be proven information theoretic secure if $k$ is chosen completely random and used only once. Because of these requirements on the key $k$, the Vernam scheme is more widely known as the \textit{one-time pad}.

\subsubsection{Practical Encryption Algorithms}
Because the one-time pad is proven information theoretic secure, it can not be broken even if the adversary has access to unlimited computing power. Although this is a desirable property, the one-time pad is not frequently used in modern cryptosystems due to its impractical key management.

Suppose Alice and Bob have a lot of secret information to share. This would require that the a priori agreed key $k$ is long enough to hide all this information. Once the size of the message $m$ becomes larger than the key $k$, Alice and Bob should agree on new random bits in $k$ to secure the remainder of their conversation. In fact, they have to agree upfront on as much random bits in $k$ as there will be bits in the message $m$.

Because such large random symmetric keys $k$ are not practical in real-life applications, block cipher modes and stream ciphers are widely used. These are algorithms that accept a fixed size symmetric key but allow to encrypt larger messages $m$ by introducing deterministic pseudo randomness. As already mentioned in Section~\ref{sec:number_theoretic_assumptions}, these algorithms require a more pragmatic view on cryptography because they only ensure that disclosure of information is computationally difficult but not impossible. Common examples of block ciphers are AES and DES. They can be used in CFB, CTR or CFB mode to name a few. Stream ciphers include Trivium and RC4. For more information on block ciphers, stream ciphers and modes of operation the reader is referred to~\cite{book:handbook_of_applied_cryptography}.

\subsection{Asymmetric Cryptography}
In the information society of today, it would not be practical if Alice should meet Bob in real-life each time she wants to privately agree on a new symmetric key $k$. Now suppose that it would be possible to encrypt messages with a key $pk$ and decrypt them with a corresponding different key $sk$. In such a setting, Bob could publish his personal encryption key $pk_{Bob}$ while keeping his decryption key $sk_{Bob}$ private thereby allowing Alice to immediately start sending private messages to Bob.

The concept of using a different key for encryption than decryption is often referred to as \textit{asymmetric cryptography}. The term \textit{public-key cryptography} describes the same idea and is interchangeably used in literature.

The concept of asymmetric cryptography bears close resemblance to the old-school mailbox system. Everyone can put letters in a mailbox, i.e. encrypt, but only a person with a privately owned key can retrieve letters, i.e. decrypt~\cite{book:PaarP10}.

\subsubsection{Trapdoor One-way Function}
Public-key cryptography revolutionised thanks to a paper from Diffie and Hellman in 1976 proposing a private key exchange algorithm, now famously known as Diffie-Hellman key exchange~\cite{art:DiffieH76}\footnote{Diffie-Hellman key exchange allows two parties that can only communicate over an insecure channel to agree on a secret while no external passive eavesdropper with limited computing power can derive the secret.}. Although Diffie-Hellman key exchange simplified the most important key management aspect of symmetric cryptography at the time, the real trigger for asymmetric cryptography appeared to be the introduction of a trapdoor one-way function.

\begin{defn}[One-way Function]
\label{def:one-way_function}
 A function $f: \left( 0, 1 \right)^* \rightarrow \left( 0, 1 \right)^*$ that is computable in polynomial time, is said to be a one-way function if for any algorithm $\mathcal{A}\left( f \left( x \right) \right)$ trying to invert $f \left( x \right)$, there exist a negligible function $\mu \left( k \right) $ such that
 \begin{equation*}
  \textrm{Pr} \left[ f \left( \mathcal{A} \left( f \left( x \right) \right) \right) = f \left( x \right) \right] \leq \mu \left( k \right)
 \end{equation*}
 where the probability is over the random choice of $x$ from the uniform random distribution on $\left( 0, 1 \right)^k$ and the random bits of the algorithm $\mathcal{A}$.
\end{defn}

A hash function (Section~\ref{sec:hash_functions}) is a practical implementation of a one-way function.

\begin{defn}[Trapdoor one-way function]
\label{def:one-way_function}
 A one-way function $f: \left( 0, 1 \right)^* \rightarrow \left( 0, 1 \right)^*$ is said to be a trapdoor one-way function if there exist a specific algorithm $\mathcal{A}' \left( f \left( x \right), \mathcal{H} \right)$ that can invert $f \left( x \right)$ based on an additional hint $\mathcal{H}$, such that for any negligible function $\mu \left( k \right)$ 
 \begin{equation*}
  \textrm{Pr} \left[ f \left( \mathcal{A}' \left( f \left( x \right) \right) \right) = f \left( x \right) \right] > \mu \left( k \right)
 \end{equation*}
 where the probability is over the random choice of $x$ from the uniform random distribution on $\left( 0, 1 \right)^k$ and the random bits of the algorithm $\mathcal{A}'$.
\end{defn} 

The Computational Diffie-Hellman problem (Section~\ref{sec:number_theoretic_assumptions}) is a trapdoor one-way function because it is hard to find $g^{ab}$ given $\left< g, g^a, g^b \right>$ but easy given $\left< g, g^a, g^b, \mathcal{H} \right>$ if the hint $\mathcal{H}$ equals $a$ or $b$.

\subsubsection{Practical Encryption Algorithms}
Trapdoor one-way functions can be used as a generic construction for asymmetric encryption by publishing all the parameters for the one-way function publicly while keeping the corresponding hint $\mathcal{H}$ private.

\subsubsection{Digital Signatures}
A digital signature resembles a handwritten signature in that it proofs a particular person has approved a particular message. However, a digital signature is harder to forge than its handwritten counterpart due to the computational hardness assumptions digital signatures rely on.

\begin{defn}[Digital signature]
\label{def:digital_signature}
 A digital signature $S_A \left( m \right)$ associates a message $m$ with a known sender $A$ in such a way that a recipient $B$ is assured about the following properties:
 \begin{enumerate}
  \item \textit{Authentication:} $B$ can be certain that $A$ is the sender of the message.
  \item \textit{Non-repudiation:} $A$ can not deny having sent the message $m$.
  \item \textit{Integrity:} $B$ can be certain that the message $m$ is delivered consistently, i.e. unaltered from how $A$ originally drafted the message $m$.
 \end{enumerate}
\end{defn}

Algorithm~\ref{alg:generic_signature_scheme} explains how a generic signature scheme is often constructed. The key pair $\left< sk_A, vk_A \right>$ is often  Note that a signature scheme only shifts the authentication problem. Verification of a signature $S_A \left( m \right)$ only ensures the message $m$ originates from the owner of the key pair $\left< sk_A, vk_A \right>$.
\begin{algorithm}
\caption{Generic Signature Scheme }
\label{alg:generic_signature_scheme}
 In a digital signature scheme each entity $A$ has a publicly known verifying key $vk_A$ and a corresponding private signing key $sk_A$. A generic signature scheme consists of two algorithms:
 \begin{enumerate}
  \item \texttt{Sign($sk_A, m$)}: Entity $A$ signs the message $m$ using its private signing key $sk_A$ resulting in a signature $S_A \left( m \right)$
  \item \texttt{Verify($pk_A, S_A \left( m \right), m$)}: Entity $B$ verifies the signature $S_A \left( m \right)$ with the public verifying key $vk_A$ of $A$. The \texttt{Verify} step returns \texttt{true} or \texttt{false} depending on the validity of the signature.
 \end{enumerate}
\end{algorithm}


\subsubsection{Certification Authorities} 

\subsubsection{OpenPGP}

\section{Conclusion}
The first part of this chapter introduced the concepts of a negligible function as well as algebraic structures such as groups and finite fields. These basic notions were used further on to define number theoretic hard problems that serve as a basis for security. Starting from the discrete logarithm assumption, several variants of the Diffie-Hellman problem were introduced eventually leading to the Gap Diffie-Hellman assumption. Notion of the Gap Diffie-Hellman assumption allowed to uncover gap groups and their use in admissible bilinear maps. The Bilinear Diffie-Hellman assumption was defined as a computationally infeasible problem for the construction of cryptographic protocols relying on bilinear maps. Finally, this chapter concluded with differences between security under random oracle assumptions and security in the standard model. 

Now the reader has knowledge of the mathematic fundaments, more advanced cryptographic constructions like identity-based encryption, broadcast encryption and distributed key generation are revealed in Chapter 3.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 
